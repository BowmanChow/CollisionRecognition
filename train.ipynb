{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "True\n['toothpaste_box', 'whiteboard_spray', 'toy_elephant', 'green_basketball', '061_foam_brick', 'shiny_toy_gun', 'salt_cylinder', 'strawberry', 'stanley_screwdriver', 'yellow_block']\n"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import torch.utils.data as data\n",
    "import torchvision.models as models\n",
    "import matplotlib.image as pli\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from PIL import ImageOps\n",
    "from PIL import ImageEnhance\n",
    "import random\n",
    "import math\n",
    "import pickle\n",
    "import glob\n",
    "import librosa\n",
    "import os\n",
    "import time\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "print(torch.cuda.is_available())\n",
    "path = './dataset/train'\n",
    "labels = os.listdir(path)\n",
    "audio_train_files = {l: glob.glob(f'{path}/{l}/[0-9][0-9]*/*.pkl') for l in labels}\n",
    "audio_val_files = {l: glob.glob(f'{path}/{l}/[0-9]/*.pkl') for l in labels}\n",
    "# print(audio_train_files)\n",
    "# print(audio_test_files)\n",
    "print(labels)\n",
    "\n",
    "is_plot = False\n",
    "\n",
    "freq_length = 57\n",
    "time_length = 221\n",
    "trainingset_size = 10000\n",
    "val_set_size = 100\n",
    "batch_size = 64 if torch.cuda.is_available() else 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from STFT import STFT\n",
    "class ImageSet(data.Dataset):\n",
    "    def __init__(self, behav):\n",
    "        if behav == 'train':\n",
    "            self.length = trainingset_size\n",
    "        elif behav == 'val':\n",
    "            self.length = val_set_size\n",
    "        else:\n",
    "            raise Exception('Error')\n",
    "        self.behav = behav\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # print(index)\n",
    "        label = index % len(labels)\n",
    "        if self.behav == 'train':\n",
    "            audio_file = random.choice(audio_train_files[labels[label]])\n",
    "        elif self.behav == 'val':\n",
    "            count = (index // len(labels)) % len(audio_val_files[labels[label]])\n",
    "            audio_file = audio_val_files[labels[label]][count]\n",
    "        else:\n",
    "            raise Exception('Error')\n",
    "        # audio_file = glob.glob(f'{path}/stanley_screwdriver/331/*.pkl')[0]\n",
    "        audio_map = STFT(audio_file,is_plot, freq_length, time_length)\n",
    "        return audio_map, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "train_loader = data.DataLoader(ImageSet('train'), batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioCNN(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super(AudioCNN, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            # 57 221\n",
    "            nn.Conv2d(in_channels=4, out_channels=64,\n",
    "                      kernel_size=(3, 11)),\n",
    "            # 55 211\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=self.layer1[0].out_channels, out_channels=64,\n",
    "                      kernel_size=(3, 10), stride=(2, 3)),\n",
    "            # 27 68\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=self.layer2[0].out_channels,\n",
    "                      out_channels=128, kernel_size=(3, 5)),\n",
    "            # 25 64\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=self.layer3[0].out_channels,\n",
    "                      out_channels=128, kernel_size=(3, 7), stride=(2, 3)),\n",
    "            # 12 20\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.layer5 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=self.layer4[0].out_channels,\n",
    "                      out_channels=256, kernel_size=(3, 5)),\n",
    "            # 10 16\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(output_size=(1, 1))\n",
    "        self.fc = nn.Linear(self.layer5[0].out_channels, len(labels))\n",
    "\n",
    "    def forward(self, input):\n",
    "        out = self.layer1(input)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.layer5(out)\n",
    "        # print(out.shape)\n",
    "        out = self.avg_pool(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "convNet = AudioCNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "state_dict = torch.load('./ConvNet.model')\n",
    "convNet.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "i = 0,  loss = 0.426588773727417,  accuracy = 0.828125\n",
      "i = 2,  loss = 0.36382123827934265,  accuracy = 0.84375\n",
      "i = 4,  loss = 0.47178855538368225,  accuracy = 0.875\n",
      "i = 6,  loss = 0.19413381814956665,  accuracy = 0.953125\n",
      "i = 8,  loss = 0.31345587968826294,  accuracy = 0.921875\n",
      "i = 10,  loss = 0.44079986214637756,  accuracy = 0.8125\n",
      "i = 12,  loss = 0.20072267949581146,  accuracy = 0.90625\n",
      "i = 14,  loss = 0.2631858289241791,  accuracy = 0.890625\n",
      "i = 16,  loss = 0.40339550375938416,  accuracy = 0.859375\n",
      "i = 18,  loss = 0.3499709963798523,  accuracy = 0.84375\n",
      "i = 20,  loss = 0.2183709442615509,  accuracy = 0.953125\n",
      "i = 22,  loss = 0.2717897891998291,  accuracy = 0.9375\n",
      "i = 24,  loss = 0.1825321763753891,  accuracy = 0.9375\n",
      "i = 26,  loss = 0.18134421110153198,  accuracy = 0.953125\n",
      "i = 28,  loss = 0.33332014083862305,  accuracy = 0.890625\n",
      "i = 30,  loss = 0.3157309591770172,  accuracy = 0.875\n",
      "i = 32,  loss = 0.2941773533821106,  accuracy = 0.921875\n",
      "i = 34,  loss = 0.298532634973526,  accuracy = 0.875\n",
      "i = 36,  loss = 0.2100505828857422,  accuracy = 0.9375\n",
      "i = 38,  loss = 0.2157302349805832,  accuracy = 0.9375\n",
      "i = 40,  loss = 0.21264749765396118,  accuracy = 0.953125\n",
      "i = 42,  loss = 0.210940420627594,  accuracy = 0.9375\n",
      "i = 44,  loss = 0.08441447466611862,  accuracy = 1.0\n",
      "i = 46,  loss = 0.12284313142299652,  accuracy = 0.96875\n",
      "i = 48,  loss = 0.18912452459335327,  accuracy = 0.9375\n",
      "i = 50,  loss = 0.2525458335876465,  accuracy = 0.90625\n",
      "i = 52,  loss = 0.20932459831237793,  accuracy = 0.9375\n",
      "i = 54,  loss = 0.1317766308784485,  accuracy = 0.953125\n",
      "i = 56,  loss = 0.30122724175453186,  accuracy = 0.9375\n",
      "i = 58,  loss = 0.19833515584468842,  accuracy = 0.921875\n",
      "i = 60,  loss = 0.19729946553707123,  accuracy = 0.953125\n",
      "i = 62,  loss = 0.24951590597629547,  accuracy = 0.9375\n",
      "i = 64,  loss = 0.2151520550251007,  accuracy = 0.90625\n",
      "i = 66,  loss = 0.14610432088375092,  accuracy = 0.9375\n",
      "i = 68,  loss = 0.09808862954378128,  accuracy = 0.953125\n",
      "i = 70,  loss = 0.2028566300868988,  accuracy = 0.921875\n",
      "i = 72,  loss = 0.2226714938879013,  accuracy = 0.9375\n",
      "i = 74,  loss = 0.23040170967578888,  accuracy = 0.90625\n",
      "i = 76,  loss = 0.27557888627052307,  accuracy = 0.921875\n",
      "i = 78,  loss = 0.37122803926467896,  accuracy = 0.859375\n",
      "i = 80,  loss = 0.2886362373828888,  accuracy = 0.90625\n",
      "i = 82,  loss = 0.09555650502443314,  accuracy = 0.984375\n",
      "i = 84,  loss = 0.3143576681613922,  accuracy = 0.90625\n",
      "i = 86,  loss = 0.28056466579437256,  accuracy = 0.90625\n",
      "i = 88,  loss = 0.09623415023088455,  accuracy = 0.984375\n",
      "i = 90,  loss = 0.14177487790584564,  accuracy = 0.96875\n",
      "i = 92,  loss = 0.18904414772987366,  accuracy = 0.9375\n",
      "i = 94,  loss = 0.2610293924808502,  accuracy = 0.90625\n",
      "i = 96,  loss = 0.20506955683231354,  accuracy = 0.921875\n",
      "i = 98,  loss = 0.19079598784446716,  accuracy = 0.9375\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-433077fe0b96>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mconvNet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvNet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlbs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;31m# print(int(round(time.time() * 1000)))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/liux19-8ViQiPRs/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/liux19-8ViQiPRs/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/liux19-8ViQiPRs/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/liux19-8ViQiPRs/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-7b5cae6848bd>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# audio_file = glob.glob(f'{path}/stanley_screwdriver/331/*.pkl')[0]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0maudio_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSTFT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mis_plot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfreq_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0maudio_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/STFT.py\u001b[0m in \u001b[0;36mSTFT\u001b[0;34m(audio_file, is_plot, freq_length, time_length)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0maudio_resample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maudio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mstft_re\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_resample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnperseg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoverlap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m384\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mstft_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstft_re\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mstft_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstft_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/liux19-8ViQiPRs/lib/python3.6/site-packages/scipy/signal/spectral.py\u001b[0m in \u001b[0;36mstft\u001b[0;34m(x, fs, window, nperseg, noverlap, nfft, detrend, return_onesided, boundary, padded, axis)\u001b[0m\n\u001b[1;32m   1171\u001b[0m                                         \u001b[0mscaling\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'spectrum'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m                                         \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'stft'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mboundary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mboundary\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1173\u001b[0;31m                                         padded=padded)\n\u001b[0m\u001b[1;32m   1174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfreqs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZxx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/liux19-8ViQiPRs/lib/python3.6/site-packages/scipy/signal/spectral.py\u001b[0m in \u001b[0;36m_spectral_helper\u001b[0;34m(x, y, fs, window, nperseg, noverlap, nfft, detrend, return_onesided, scaling, axis, mode, boundary, padded)\u001b[0m\n\u001b[1;32m   1828\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1829\u001b[0m     \u001b[0;31m# Perform the windowed FFTs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1830\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_fft_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetrend_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnperseg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoverlap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnfft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1832\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msame_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/liux19-8ViQiPRs/lib/python3.6/site-packages/scipy/signal/spectral.py\u001b[0m in \u001b[0;36m_fft_helper\u001b[0;34m(x, win, detrend_func, nperseg, noverlap, nfft, sides)\u001b[0m\n\u001b[1;32m   1913\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1914\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msp_fft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrfft\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1915\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnfft\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1917\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/liux19-8ViQiPRs/lib/python3.6/site-packages/scipy/fft/_backend.py\u001b[0m in \u001b[0;36m__ua_function__\u001b[0;34m(method, args, kwargs)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/liux19-8ViQiPRs/lib/python3.6/site-packages/scipy/fft/_pocketfft/basic.py\u001b[0m in \u001b[0;36mr2c\u001b[0;34m(forward, x, n, axis, norm, overwrite_x, workers, plan)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;31m# Note: overwrite_x is not utilised\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mpfft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mr2c\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(convNet.parameters(), lr=0.01)\n",
    "\n",
    "convNet.train()\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device('cpu')\n",
    "convNet = convNet.to(device)\n",
    "\n",
    "for i, (imgs, lbs) in enumerate(train_loader):\n",
    "    # print(int(round(time.time() * 1000)))\n",
    "    imgs = imgs.float().to(device)\n",
    "    lbs = lbs.to(device)\n",
    "    outputs = convNet(imgs)\n",
    "    loss = loss_func(outputs, lbs)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    predict = torch.argmax(F.softmax(outputs, dim=1), dim=1)\n",
    "    # print(int(round(time.time() * 1000)))\n",
    "    if i % 2 == 0:\n",
    "        print(f\"i = {i},  loss = {loss},  accuracy = {float(sum(lbs == predict))/float(lbs.size(0))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存模型， 请谨慎操作， 会覆盖文件中的模型\n",
    "torch.save(convNet.state_dict(), './ConvNet.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "i = 0, \n",
      " lables = tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3,\n",
      "        4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7,\n",
      "        8, 9], device='cuda:0'), \n",
      " predict = tensor([0, 1, 2, 3, 4, 5, 6, 7, 5, 9, 0, 1, 2, 3, 4, 5, 6, 6, 5, 9, 0, 1, 2, 3,\n",
      "        4, 5, 6, 7, 5, 9, 0, 1, 2, 0, 4, 5, 9, 7, 8, 9, 0, 6, 8, 3, 4, 5, 0, 7,\n",
      "        5, 9], device='cuda:0')  \n",
      " accuracy = 0.8\n",
      "i = 1, \n",
      " lables = tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3,\n",
      "        4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7,\n",
      "        8, 9], device='cuda:0'), \n",
      " predict = tensor([0, 0, 2, 3, 4, 4, 5, 7, 8, 9, 0, 1, 5, 3, 4, 5, 6, 7, 6, 9, 0, 1, 2, 3,\n",
      "        4, 5, 9, 7, 8, 9, 0, 6, 4, 3, 4, 5, 6, 7, 9, 9, 0, 1, 5, 3, 4, 5, 6, 7,\n",
      "        5, 9], device='cuda:0')  \n",
      " accuracy = 0.78\n"
     ]
    }
   ],
   "source": [
    "val_loader = data.DataLoader(ImageSet('val'), batch_size=50, shuffle=False)\n",
    "\n",
    "convNet.eval()\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device('cpu')\n",
    "convNet = convNet.to(device)\n",
    "\n",
    "for i, (imgs, lbs) in enumerate(val_loader):\n",
    "    # print(int(round(time.time() * 1000)))\n",
    "    imgs = imgs.float().to(device)\n",
    "    lbs = lbs.to(device)\n",
    "    outputs = convNet(imgs)\n",
    "    predict = torch.argmax(F.softmax(outputs, dim=1), dim=1)\n",
    "    # print(int(round(time.time() * 1000)))\n",
    "    if i % 1 == 0:\n",
    "        print(f\"i = {i}, \\n lables = {lbs}, \\n predict = {predict}  \\n accuracy = {float(sum(lbs == predict))/float(lbs.size(0))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from STFT import STFT\n",
    "audio_test_files = glob.glob(f'./dataset/task2/test/*/*.pkl')\n",
    "class TestSet(data.Dataset):\n",
    "    def __init__(self):\n",
    "        self.length = len(audio_test_files)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        audio_file = audio_test_files[index]\n",
    "        audio_map = STFT(audio_file,is_plot, freq_length, time_length)\n",
    "        return audio_map, audio_file\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "test_loader = data.DataLoader(TestSet(), batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "i = 0,  \n",
      "    predict = tensor([6, 7, 1, 5, 0, 1, 3, 5, 9, 7, 9, 9, 1, 3, 2, 3, 1, 0, 9, 5, 9, 0, 2, 3,\n",
      "        8, 8, 6, 8, 6, 2, 1, 4, 1, 7, 6, 3, 0, 8, 2, 9, 4, 3, 0, 0, 3, 9, 5, 8,\n",
      "        1, 2, 7, 3, 9, 9, 1, 3, 9, 5, 6, 7, 1, 0, 0, 6], device='cuda:0')\n",
      "i = 1,  \n",
      "    predict = tensor([4, 4, 1, 3, 2, 8, 8, 6, 4, 4, 9, 5, 9, 9, 4, 2, 5, 7, 8, 6, 3, 9, 0, 1,\n",
      "        9, 7, 9, 3, 3, 2, 2, 5, 2, 6, 0, 0, 7, 9, 4, 1, 5, 5, 3, 9, 7, 5, 1, 5,\n",
      "        0, 6, 7, 1, 8, 9, 8, 6, 7, 2, 5, 0, 7, 3, 9, 8], device='cuda:0')\n",
      "i = 2,  \n",
      "    predict = tensor([4, 5, 9, 4, 1, 0, 9, 5, 3, 6, 6, 9, 0, 9, 6, 8, 0, 2, 3, 6, 9, 5, 3, 9,\n",
      "        9, 8, 8, 6, 9, 0, 3, 7, 7, 7, 6, 2, 7, 2, 0, 0, 0, 8, 1, 6, 2, 0, 0, 9,\n",
      "        3, 1, 6, 3, 5, 3, 4, 4, 5, 7, 7, 3, 3, 3, 1, 5], device='cuda:0')\n",
      "i = 3,  \n",
      "    predict = tensor([2, 0, 9, 7, 9, 3, 2, 0, 4, 8, 7, 0, 1, 3, 1, 2, 9, 3, 2, 1, 6, 1, 0, 2,\n",
      "        4, 2, 8, 7, 5, 7, 5, 8, 5, 2, 3, 6, 6, 6, 7, 6, 9, 7, 2, 5, 1, 3, 9, 7,\n",
      "        5, 3, 7, 7, 2, 5, 9, 9, 1, 9, 0, 4, 7, 0, 7, 3], device='cuda:0')\n",
      "i = 4,  \n",
      "    predict = tensor([3, 5, 8, 6, 2, 1, 8, 7, 6, 9, 5, 9, 3, 2, 3, 3, 6, 7, 3, 6, 7, 5, 0, 3,\n",
      "        5, 1, 1, 4, 8, 5, 4, 3, 3, 8, 6, 3, 9, 3, 5, 8, 4, 0, 2, 9, 1, 7, 6, 4,\n",
      "        8, 3, 9, 6, 6, 5, 8, 4, 0, 8, 0, 9, 7, 1, 7, 8], device='cuda:0')\n",
      "i = 5,  \n",
      "    predict = tensor([6, 8, 8, 6, 4, 6, 1, 3, 9, 3, 6, 5, 9, 5, 7, 3, 9, 3, 8, 1, 9, 7, 9, 8,\n",
      "        9, 4, 6, 5, 6, 8, 9, 2, 5, 8, 6, 7, 8, 3, 0, 5, 8, 8, 4, 9, 1, 9, 0, 6,\n",
      "        0, 5, 0, 7, 2, 6, 3, 9, 1, 8, 9, 3, 1, 3, 3, 5], device='cuda:0')\n",
      "i = 6,  \n",
      "    predict = tensor([3, 6, 4, 5, 3, 5, 7, 3, 1, 8, 9, 5, 9, 4, 8, 2, 9, 5, 3, 1, 6, 1, 3, 6,\n",
      "        7, 5, 7, 6, 9, 9, 7, 1, 0, 0, 9, 8, 1, 4, 6, 0, 1, 2, 3, 2, 2, 1, 4, 1,\n",
      "        5, 7, 3, 1, 5, 5, 3, 6, 9, 6, 7, 5, 3, 8, 5, 9], device='cuda:0')\n",
      "i = 7,  \n",
      "    predict = tensor([2, 7, 3, 2, 2, 1, 2, 3, 7, 7, 6, 4, 2, 8, 9, 9, 9, 6, 7, 0, 3, 9, 1, 7,\n",
      "        2, 2, 0, 3, 4, 0, 3, 9, 2, 2, 0, 6, 4, 7, 2, 6, 3, 0, 1, 5, 4, 3, 7, 7,\n",
      "        8, 2, 1, 8], device='cuda:0')\n",
      "['./dataset/task2/test/6/audio_0028.pkl', './dataset/task2/test/6/audio_0022.pkl', './dataset/task2/test/6/audio_0011.pkl', './dataset/task2/test/6/audio_0017.pkl', './dataset/task2/test/6/audio_0047.pkl', './dataset/task2/test/6/audio_0003.pkl', './dataset/task2/test/6/audio_0006.pkl', './dataset/task2/test/6/audio_0002.pkl', './dataset/task2/test/6/audio_0024.pkl', './dataset/task2/test/6/audio_0004.pkl', './dataset/task2/test/6/audio_0019.pkl', './dataset/task2/test/6/audio_0000.pkl', './dataset/task2/test/6/audio_0033.pkl', './dataset/task2/test/6/audio_0026.pkl', './dataset/task2/test/6/audio_0023.pkl', './dataset/task2/test/6/audio_0042.pkl', './dataset/task2/test/6/audio_0008.pkl', './dataset/task2/test/6/audio_0010.pkl', './dataset/task2/test/6/audio_0012.pkl', './dataset/task2/test/6/audio_0029.pkl', './dataset/task2/test/6/audio_0027.pkl', './dataset/task2/test/6/audio_0018.pkl', './dataset/task2/test/6/audio_0031.pkl', './dataset/task2/test/6/audio_0038.pkl', './dataset/task2/test/6/audio_0048.pkl', './dataset/task2/test/6/audio_0035.pkl', './dataset/task2/test/6/audio_0037.pkl', './dataset/task2/test/6/audio_0021.pkl', './dataset/task2/test/6/audio_0045.pkl', './dataset/task2/test/6/audio_0043.pkl', './dataset/task2/test/6/audio_0030.pkl', './dataset/task2/test/6/audio_0041.pkl', './dataset/task2/test/6/audio_0032.pkl', './dataset/task2/test/6/audio_0039.pkl', './dataset/task2/test/6/audio_0049.pkl', './dataset/task2/test/6/audio_0025.pkl', './dataset/task2/test/6/audio_0001.pkl', './dataset/task2/test/6/audio_0034.pkl', './dataset/task2/test/6/audio_0005.pkl', './dataset/task2/test/6/audio_0014.pkl', './dataset/task2/test/6/audio_0046.pkl', './dataset/task2/test/6/audio_0009.pkl', './dataset/task2/test/6/audio_0040.pkl', './dataset/task2/test/6/audio_0044.pkl', './dataset/task2/test/6/audio_0013.pkl', './dataset/task2/test/6/audio_0020.pkl', './dataset/task2/test/6/audio_0016.pkl', './dataset/task2/test/6/audio_0036.pkl', './dataset/task2/test/6/audio_0015.pkl', './dataset/task2/test/6/audio_0007.pkl', './dataset/task2/test/8/audio_0028.pkl', './dataset/task2/test/8/audio_0022.pkl', './dataset/task2/test/8/audio_0011.pkl', './dataset/task2/test/8/audio_0017.pkl', './dataset/task2/test/8/audio_0047.pkl', './dataset/task2/test/8/audio_0003.pkl', './dataset/task2/test/8/audio_0006.pkl', './dataset/task2/test/8/audio_0002.pkl', './dataset/task2/test/8/audio_0024.pkl', './dataset/task2/test/8/audio_0004.pkl', './dataset/task2/test/8/audio_0019.pkl', './dataset/task2/test/8/audio_0000.pkl', './dataset/task2/test/8/audio_0033.pkl', './dataset/task2/test/8/audio_0026.pkl', './dataset/task2/test/8/audio_0023.pkl', './dataset/task2/test/8/audio_0042.pkl', './dataset/task2/test/8/audio_0008.pkl', './dataset/task2/test/8/audio_0010.pkl', './dataset/task2/test/8/audio_0012.pkl', './dataset/task2/test/8/audio_0029.pkl', './dataset/task2/test/8/audio_0027.pkl', './dataset/task2/test/8/audio_0018.pkl', './dataset/task2/test/8/audio_0031.pkl', './dataset/task2/test/8/audio_0038.pkl', './dataset/task2/test/8/audio_0048.pkl', './dataset/task2/test/8/audio_0035.pkl', './dataset/task2/test/8/audio_0037.pkl', './dataset/task2/test/8/audio_0021.pkl', './dataset/task2/test/8/audio_0045.pkl', './dataset/task2/test/8/audio_0043.pkl', './dataset/task2/test/8/audio_0030.pkl', './dataset/task2/test/8/audio_0041.pkl', './dataset/task2/test/8/audio_0032.pkl', './dataset/task2/test/8/audio_0039.pkl', './dataset/task2/test/8/audio_0049.pkl', './dataset/task2/test/8/audio_0025.pkl', './dataset/task2/test/8/audio_0001.pkl', './dataset/task2/test/8/audio_0034.pkl', './dataset/task2/test/8/audio_0005.pkl', './dataset/task2/test/8/audio_0014.pkl', './dataset/task2/test/8/audio_0046.pkl', './dataset/task2/test/8/audio_0009.pkl', './dataset/task2/test/8/audio_0040.pkl', './dataset/task2/test/8/audio_0044.pkl', './dataset/task2/test/8/audio_0013.pkl', './dataset/task2/test/8/audio_0020.pkl', './dataset/task2/test/8/audio_0016.pkl', './dataset/task2/test/8/audio_0036.pkl', './dataset/task2/test/8/audio_0015.pkl', './dataset/task2/test/8/audio_0007.pkl', './dataset/task2/test/4/audio_0028.pkl', './dataset/task2/test/4/audio_0022.pkl', './dataset/task2/test/4/audio_0011.pkl', './dataset/task2/test/4/audio_0017.pkl', './dataset/task2/test/4/audio_0047.pkl', './dataset/task2/test/4/audio_0003.pkl', './dataset/task2/test/4/audio_0006.pkl', './dataset/task2/test/4/audio_0002.pkl', './dataset/task2/test/4/audio_0024.pkl', './dataset/task2/test/4/audio_0004.pkl', './dataset/task2/test/4/audio_0019.pkl', './dataset/task2/test/4/audio_0000.pkl', './dataset/task2/test/4/audio_0033.pkl', './dataset/task2/test/4/audio_0026.pkl', './dataset/task2/test/4/audio_0023.pkl', './dataset/task2/test/4/audio_0042.pkl', './dataset/task2/test/4/audio_0008.pkl', './dataset/task2/test/4/audio_0010.pkl', './dataset/task2/test/4/audio_0012.pkl', './dataset/task2/test/4/audio_0029.pkl', './dataset/task2/test/4/audio_0027.pkl', './dataset/task2/test/4/audio_0018.pkl', './dataset/task2/test/4/audio_0031.pkl', './dataset/task2/test/4/audio_0038.pkl', './dataset/task2/test/4/audio_0048.pkl', './dataset/task2/test/4/audio_0035.pkl', './dataset/task2/test/4/audio_0037.pkl', './dataset/task2/test/4/audio_0021.pkl', './dataset/task2/test/4/audio_0045.pkl', './dataset/task2/test/4/audio_0043.pkl', './dataset/task2/test/4/audio_0030.pkl', './dataset/task2/test/4/audio_0041.pkl', './dataset/task2/test/4/audio_0032.pkl', './dataset/task2/test/4/audio_0039.pkl', './dataset/task2/test/4/audio_0049.pkl', './dataset/task2/test/4/audio_0025.pkl', './dataset/task2/test/4/audio_0001.pkl', './dataset/task2/test/4/audio_0034.pkl', './dataset/task2/test/4/audio_0005.pkl', './dataset/task2/test/4/audio_0014.pkl', './dataset/task2/test/4/audio_0046.pkl', './dataset/task2/test/4/audio_0009.pkl', './dataset/task2/test/4/audio_0040.pkl', './dataset/task2/test/4/audio_0044.pkl', './dataset/task2/test/4/audio_0013.pkl', './dataset/task2/test/4/audio_0020.pkl', './dataset/task2/test/4/audio_0016.pkl', './dataset/task2/test/4/audio_0036.pkl', './dataset/task2/test/4/audio_0015.pkl', './dataset/task2/test/4/audio_0007.pkl', './dataset/task2/test/2/audio_0028.pkl', './dataset/task2/test/2/audio_0022.pkl', './dataset/task2/test/2/audio_0011.pkl', './dataset/task2/test/2/audio_0017.pkl', './dataset/task2/test/2/audio_0047.pkl', './dataset/task2/test/2/audio_0003.pkl', './dataset/task2/test/2/audio_0006.pkl', './dataset/task2/test/2/audio_0002.pkl', './dataset/task2/test/2/audio_0024.pkl', './dataset/task2/test/2/audio_0004.pkl', './dataset/task2/test/2/audio_0019.pkl', './dataset/task2/test/2/audio_0000.pkl', './dataset/task2/test/2/audio_0033.pkl', './dataset/task2/test/2/audio_0026.pkl', './dataset/task2/test/2/audio_0023.pkl', './dataset/task2/test/2/audio_0042.pkl', './dataset/task2/test/2/audio_0008.pkl', './dataset/task2/test/2/audio_0010.pkl', './dataset/task2/test/2/audio_0012.pkl', './dataset/task2/test/2/audio_0029.pkl', './dataset/task2/test/2/audio_0027.pkl', './dataset/task2/test/2/audio_0018.pkl', './dataset/task2/test/2/audio_0031.pkl', './dataset/task2/test/2/audio_0038.pkl', './dataset/task2/test/2/audio_0048.pkl', './dataset/task2/test/2/audio_0035.pkl', './dataset/task2/test/2/audio_0037.pkl', './dataset/task2/test/2/audio_0021.pkl', './dataset/task2/test/2/audio_0045.pkl', './dataset/task2/test/2/audio_0043.pkl', './dataset/task2/test/2/audio_0030.pkl', './dataset/task2/test/2/audio_0041.pkl', './dataset/task2/test/2/audio_0032.pkl', './dataset/task2/test/2/audio_0039.pkl', './dataset/task2/test/2/audio_0049.pkl', './dataset/task2/test/2/audio_0025.pkl', './dataset/task2/test/2/audio_0001.pkl', './dataset/task2/test/2/audio_0034.pkl', './dataset/task2/test/2/audio_0005.pkl', './dataset/task2/test/2/audio_0014.pkl', './dataset/task2/test/2/audio_0046.pkl', './dataset/task2/test/2/audio_0009.pkl', './dataset/task2/test/2/audio_0040.pkl', './dataset/task2/test/2/audio_0044.pkl', './dataset/task2/test/2/audio_0013.pkl', './dataset/task2/test/2/audio_0020.pkl', './dataset/task2/test/2/audio_0016.pkl', './dataset/task2/test/2/audio_0036.pkl', './dataset/task2/test/2/audio_0015.pkl', './dataset/task2/test/2/audio_0007.pkl', './dataset/task2/test/3/audio_0028.pkl', './dataset/task2/test/3/audio_0022.pkl', './dataset/task2/test/3/audio_0011.pkl', './dataset/task2/test/3/audio_0017.pkl', './dataset/task2/test/3/audio_0047.pkl', './dataset/task2/test/3/audio_0003.pkl', './dataset/task2/test/3/audio_0006.pkl', './dataset/task2/test/3/audio_0002.pkl', './dataset/task2/test/3/audio_0024.pkl', './dataset/task2/test/3/audio_0004.pkl', './dataset/task2/test/3/audio_0019.pkl', './dataset/task2/test/3/audio_0000.pkl', './dataset/task2/test/3/audio_0033.pkl', './dataset/task2/test/3/audio_0026.pkl', './dataset/task2/test/3/audio_0023.pkl', './dataset/task2/test/3/audio_0042.pkl', './dataset/task2/test/3/audio_0008.pkl', './dataset/task2/test/3/audio_0010.pkl', './dataset/task2/test/3/audio_0012.pkl', './dataset/task2/test/3/audio_0029.pkl', './dataset/task2/test/3/audio_0027.pkl', './dataset/task2/test/3/audio_0018.pkl', './dataset/task2/test/3/audio_0031.pkl', './dataset/task2/test/3/audio_0038.pkl', './dataset/task2/test/3/audio_0048.pkl', './dataset/task2/test/3/audio_0035.pkl', './dataset/task2/test/3/audio_0037.pkl', './dataset/task2/test/3/audio_0021.pkl', './dataset/task2/test/3/audio_0045.pkl', './dataset/task2/test/3/audio_0043.pkl', './dataset/task2/test/3/audio_0030.pkl', './dataset/task2/test/3/audio_0041.pkl', './dataset/task2/test/3/audio_0032.pkl', './dataset/task2/test/3/audio_0039.pkl', './dataset/task2/test/3/audio_0049.pkl', './dataset/task2/test/3/audio_0025.pkl', './dataset/task2/test/3/audio_0001.pkl', './dataset/task2/test/3/audio_0034.pkl', './dataset/task2/test/3/audio_0005.pkl', './dataset/task2/test/3/audio_0014.pkl', './dataset/task2/test/3/audio_0046.pkl', './dataset/task2/test/3/audio_0009.pkl', './dataset/task2/test/3/audio_0040.pkl', './dataset/task2/test/3/audio_0044.pkl', './dataset/task2/test/3/audio_0013.pkl', './dataset/task2/test/3/audio_0020.pkl', './dataset/task2/test/3/audio_0016.pkl', './dataset/task2/test/3/audio_0036.pkl', './dataset/task2/test/3/audio_0015.pkl', './dataset/task2/test/3/audio_0007.pkl', './dataset/task2/test/5/audio_0028.pkl', './dataset/task2/test/5/audio_0022.pkl', './dataset/task2/test/5/audio_0011.pkl', './dataset/task2/test/5/audio_0017.pkl', './dataset/task2/test/5/audio_0047.pkl', './dataset/task2/test/5/audio_0003.pkl', './dataset/task2/test/5/audio_0006.pkl', './dataset/task2/test/5/audio_0002.pkl', './dataset/task2/test/5/audio_0024.pkl', './dataset/task2/test/5/audio_0004.pkl', './dataset/task2/test/5/audio_0019.pkl', './dataset/task2/test/5/audio_0000.pkl', './dataset/task2/test/5/audio_0033.pkl', './dataset/task2/test/5/audio_0026.pkl', './dataset/task2/test/5/audio_0023.pkl', './dataset/task2/test/5/audio_0042.pkl', './dataset/task2/test/5/audio_0008.pkl', './dataset/task2/test/5/audio_0010.pkl', './dataset/task2/test/5/audio_0012.pkl', './dataset/task2/test/5/audio_0029.pkl', './dataset/task2/test/5/audio_0027.pkl', './dataset/task2/test/5/audio_0018.pkl', './dataset/task2/test/5/audio_0031.pkl', './dataset/task2/test/5/audio_0038.pkl', './dataset/task2/test/5/audio_0048.pkl', './dataset/task2/test/5/audio_0035.pkl', './dataset/task2/test/5/audio_0037.pkl', './dataset/task2/test/5/audio_0021.pkl', './dataset/task2/test/5/audio_0045.pkl', './dataset/task2/test/5/audio_0043.pkl', './dataset/task2/test/5/audio_0030.pkl', './dataset/task2/test/5/audio_0041.pkl', './dataset/task2/test/5/audio_0032.pkl', './dataset/task2/test/5/audio_0039.pkl', './dataset/task2/test/5/audio_0049.pkl', './dataset/task2/test/5/audio_0025.pkl', './dataset/task2/test/5/audio_0001.pkl', './dataset/task2/test/5/audio_0034.pkl', './dataset/task2/test/5/audio_0005.pkl', './dataset/task2/test/5/audio_0014.pkl', './dataset/task2/test/5/audio_0046.pkl', './dataset/task2/test/5/audio_0009.pkl', './dataset/task2/test/5/audio_0040.pkl', './dataset/task2/test/5/audio_0044.pkl', './dataset/task2/test/5/audio_0013.pkl', './dataset/task2/test/5/audio_0020.pkl', './dataset/task2/test/5/audio_0016.pkl', './dataset/task2/test/5/audio_0036.pkl', './dataset/task2/test/5/audio_0015.pkl', './dataset/task2/test/5/audio_0007.pkl', './dataset/task2/test/9/audio_0028.pkl', './dataset/task2/test/9/audio_0022.pkl', './dataset/task2/test/9/audio_0011.pkl', './dataset/task2/test/9/audio_0017.pkl', './dataset/task2/test/9/audio_0047.pkl', './dataset/task2/test/9/audio_0003.pkl', './dataset/task2/test/9/audio_0006.pkl', './dataset/task2/test/9/audio_0002.pkl', './dataset/task2/test/9/audio_0024.pkl', './dataset/task2/test/9/audio_0004.pkl', './dataset/task2/test/9/audio_0019.pkl', './dataset/task2/test/9/audio_0000.pkl', './dataset/task2/test/9/audio_0033.pkl', './dataset/task2/test/9/audio_0026.pkl', './dataset/task2/test/9/audio_0023.pkl', './dataset/task2/test/9/audio_0042.pkl', './dataset/task2/test/9/audio_0008.pkl', './dataset/task2/test/9/audio_0010.pkl', './dataset/task2/test/9/audio_0012.pkl', './dataset/task2/test/9/audio_0029.pkl', './dataset/task2/test/9/audio_0027.pkl', './dataset/task2/test/9/audio_0018.pkl', './dataset/task2/test/9/audio_0031.pkl', './dataset/task2/test/9/audio_0038.pkl', './dataset/task2/test/9/audio_0048.pkl', './dataset/task2/test/9/audio_0035.pkl', './dataset/task2/test/9/audio_0037.pkl', './dataset/task2/test/9/audio_0021.pkl', './dataset/task2/test/9/audio_0045.pkl', './dataset/task2/test/9/audio_0043.pkl', './dataset/task2/test/9/audio_0030.pkl', './dataset/task2/test/9/audio_0041.pkl', './dataset/task2/test/9/audio_0032.pkl', './dataset/task2/test/9/audio_0039.pkl', './dataset/task2/test/9/audio_0049.pkl', './dataset/task2/test/9/audio_0025.pkl', './dataset/task2/test/9/audio_0001.pkl', './dataset/task2/test/9/audio_0034.pkl', './dataset/task2/test/9/audio_0005.pkl', './dataset/task2/test/9/audio_0014.pkl', './dataset/task2/test/9/audio_0046.pkl', './dataset/task2/test/9/audio_0009.pkl', './dataset/task2/test/9/audio_0040.pkl', './dataset/task2/test/9/audio_0044.pkl', './dataset/task2/test/9/audio_0013.pkl', './dataset/task2/test/9/audio_0020.pkl', './dataset/task2/test/9/audio_0016.pkl', './dataset/task2/test/9/audio_0036.pkl', './dataset/task2/test/9/audio_0015.pkl', './dataset/task2/test/9/audio_0007.pkl', './dataset/task2/test/1/audio_0028.pkl', './dataset/task2/test/1/audio_0022.pkl', './dataset/task2/test/1/audio_0011.pkl', './dataset/task2/test/1/audio_0017.pkl', './dataset/task2/test/1/audio_0047.pkl', './dataset/task2/test/1/audio_0003.pkl', './dataset/task2/test/1/audio_0006.pkl', './dataset/task2/test/1/audio_0002.pkl', './dataset/task2/test/1/audio_0024.pkl', './dataset/task2/test/1/audio_0004.pkl', './dataset/task2/test/1/audio_0019.pkl', './dataset/task2/test/1/audio_0000.pkl', './dataset/task2/test/1/audio_0033.pkl', './dataset/task2/test/1/audio_0026.pkl', './dataset/task2/test/1/audio_0023.pkl', './dataset/task2/test/1/audio_0042.pkl', './dataset/task2/test/1/audio_0008.pkl', './dataset/task2/test/1/audio_0010.pkl', './dataset/task2/test/1/audio_0012.pkl', './dataset/task2/test/1/audio_0029.pkl', './dataset/task2/test/1/audio_0027.pkl', './dataset/task2/test/1/audio_0018.pkl', './dataset/task2/test/1/audio_0031.pkl', './dataset/task2/test/1/audio_0038.pkl', './dataset/task2/test/1/audio_0048.pkl', './dataset/task2/test/1/audio_0035.pkl', './dataset/task2/test/1/audio_0037.pkl', './dataset/task2/test/1/audio_0021.pkl', './dataset/task2/test/1/audio_0045.pkl', './dataset/task2/test/1/audio_0043.pkl', './dataset/task2/test/1/audio_0030.pkl', './dataset/task2/test/1/audio_0041.pkl', './dataset/task2/test/1/audio_0032.pkl', './dataset/task2/test/1/audio_0039.pkl', './dataset/task2/test/1/audio_0049.pkl', './dataset/task2/test/1/audio_0025.pkl', './dataset/task2/test/1/audio_0001.pkl', './dataset/task2/test/1/audio_0034.pkl', './dataset/task2/test/1/audio_0005.pkl', './dataset/task2/test/1/audio_0014.pkl', './dataset/task2/test/1/audio_0046.pkl', './dataset/task2/test/1/audio_0009.pkl', './dataset/task2/test/1/audio_0040.pkl', './dataset/task2/test/1/audio_0044.pkl', './dataset/task2/test/1/audio_0013.pkl', './dataset/task2/test/1/audio_0020.pkl', './dataset/task2/test/1/audio_0016.pkl', './dataset/task2/test/1/audio_0036.pkl', './dataset/task2/test/1/audio_0015.pkl', './dataset/task2/test/1/audio_0007.pkl', './dataset/task2/test/7/audio_0028.pkl', './dataset/task2/test/7/audio_0022.pkl', './dataset/task2/test/7/audio_0011.pkl', './dataset/task2/test/7/audio_0017.pkl', './dataset/task2/test/7/audio_0047.pkl', './dataset/task2/test/7/audio_0003.pkl', './dataset/task2/test/7/audio_0006.pkl', './dataset/task2/test/7/audio_0002.pkl', './dataset/task2/test/7/audio_0024.pkl', './dataset/task2/test/7/audio_0004.pkl', './dataset/task2/test/7/audio_0019.pkl', './dataset/task2/test/7/audio_0000.pkl', './dataset/task2/test/7/audio_0033.pkl', './dataset/task2/test/7/audio_0026.pkl', './dataset/task2/test/7/audio_0023.pkl', './dataset/task2/test/7/audio_0042.pkl', './dataset/task2/test/7/audio_0008.pkl', './dataset/task2/test/7/audio_0010.pkl', './dataset/task2/test/7/audio_0012.pkl', './dataset/task2/test/7/audio_0029.pkl', './dataset/task2/test/7/audio_0027.pkl', './dataset/task2/test/7/audio_0018.pkl', './dataset/task2/test/7/audio_0031.pkl', './dataset/task2/test/7/audio_0038.pkl', './dataset/task2/test/7/audio_0048.pkl', './dataset/task2/test/7/audio_0035.pkl', './dataset/task2/test/7/audio_0037.pkl', './dataset/task2/test/7/audio_0021.pkl', './dataset/task2/test/7/audio_0045.pkl', './dataset/task2/test/7/audio_0043.pkl', './dataset/task2/test/7/audio_0030.pkl', './dataset/task2/test/7/audio_0041.pkl', './dataset/task2/test/7/audio_0032.pkl', './dataset/task2/test/7/audio_0039.pkl', './dataset/task2/test/7/audio_0049.pkl', './dataset/task2/test/7/audio_0025.pkl', './dataset/task2/test/7/audio_0001.pkl', './dataset/task2/test/7/audio_0034.pkl', './dataset/task2/test/7/audio_0005.pkl', './dataset/task2/test/7/audio_0014.pkl', './dataset/task2/test/7/audio_0046.pkl', './dataset/task2/test/7/audio_0009.pkl', './dataset/task2/test/7/audio_0040.pkl', './dataset/task2/test/7/audio_0044.pkl', './dataset/task2/test/7/audio_0013.pkl', './dataset/task2/test/7/audio_0020.pkl', './dataset/task2/test/7/audio_0016.pkl', './dataset/task2/test/7/audio_0036.pkl', './dataset/task2/test/7/audio_0015.pkl', './dataset/task2/test/7/audio_0007.pkl', './dataset/task2/test/0/audio_0028.pkl', './dataset/task2/test/0/audio_0022.pkl', './dataset/task2/test/0/audio_0011.pkl', './dataset/task2/test/0/audio_0017.pkl', './dataset/task2/test/0/audio_0047.pkl', './dataset/task2/test/0/audio_0003.pkl', './dataset/task2/test/0/audio_0006.pkl', './dataset/task2/test/0/audio_0002.pkl', './dataset/task2/test/0/audio_0024.pkl', './dataset/task2/test/0/audio_0004.pkl', './dataset/task2/test/0/audio_0019.pkl', './dataset/task2/test/0/audio_0000.pkl', './dataset/task2/test/0/audio_0033.pkl', './dataset/task2/test/0/audio_0026.pkl', './dataset/task2/test/0/audio_0023.pkl', './dataset/task2/test/0/audio_0042.pkl', './dataset/task2/test/0/audio_0008.pkl', './dataset/task2/test/0/audio_0010.pkl', './dataset/task2/test/0/audio_0012.pkl', './dataset/task2/test/0/audio_0029.pkl', './dataset/task2/test/0/audio_0027.pkl', './dataset/task2/test/0/audio_0018.pkl', './dataset/task2/test/0/audio_0031.pkl', './dataset/task2/test/0/audio_0038.pkl', './dataset/task2/test/0/audio_0048.pkl', './dataset/task2/test/0/audio_0035.pkl', './dataset/task2/test/0/audio_0037.pkl', './dataset/task2/test/0/audio_0021.pkl', './dataset/task2/test/0/audio_0045.pkl', './dataset/task2/test/0/audio_0043.pkl', './dataset/task2/test/0/audio_0030.pkl', './dataset/task2/test/0/audio_0041.pkl', './dataset/task2/test/0/audio_0032.pkl', './dataset/task2/test/0/audio_0039.pkl', './dataset/task2/test/0/audio_0049.pkl', './dataset/task2/test/0/audio_0025.pkl', './dataset/task2/test/0/audio_0001.pkl', './dataset/task2/test/0/audio_0034.pkl', './dataset/task2/test/0/audio_0005.pkl', './dataset/task2/test/0/audio_0014.pkl', './dataset/task2/test/0/audio_0046.pkl', './dataset/task2/test/0/audio_0009.pkl', './dataset/task2/test/0/audio_0040.pkl', './dataset/task2/test/0/audio_0044.pkl', './dataset/task2/test/0/audio_0013.pkl', './dataset/task2/test/0/audio_0020.pkl', './dataset/task2/test/0/audio_0016.pkl', './dataset/task2/test/0/audio_0036.pkl', './dataset/task2/test/0/audio_0015.pkl', './dataset/task2/test/0/audio_0007.pkl']\n",
      "[6, 7, 1, 5, 0, 1, 3, 5, 9, 7, 9, 9, 1, 3, 2, 3, 1, 0, 9, 5, 9, 0, 2, 3, 8, 8, 6, 8, 6, 2, 1, 4, 1, 7, 6, 3, 0, 8, 2, 9, 4, 3, 0, 0, 3, 9, 5, 8, 1, 2, 7, 3, 9, 9, 1, 3, 9, 5, 6, 7, 1, 0, 0, 6, 4, 4, 1, 3, 2, 8, 8, 6, 4, 4, 9, 5, 9, 9, 4, 2, 5, 7, 8, 6, 3, 9, 0, 1, 9, 7, 9, 3, 3, 2, 2, 5, 2, 6, 0, 0, 7, 9, 4, 1, 5, 5, 3, 9, 7, 5, 1, 5, 0, 6, 7, 1, 8, 9, 8, 6, 7, 2, 5, 0, 7, 3, 9, 8, 4, 5, 9, 4, 1, 0, 9, 5, 3, 6, 6, 9, 0, 9, 6, 8, 0, 2, 3, 6, 9, 5, 3, 9, 9, 8, 8, 6, 9, 0, 3, 7, 7, 7, 6, 2, 7, 2, 0, 0, 0, 8, 1, 6, 2, 0, 0, 9, 3, 1, 6, 3, 5, 3, 4, 4, 5, 7, 7, 3, 3, 3, 1, 5, 2, 0, 9, 7, 9, 3, 2, 0, 4, 8, 7, 0, 1, 3, 1, 2, 9, 3, 2, 1, 6, 1, 0, 2, 4, 2, 8, 7, 5, 7, 5, 8, 5, 2, 3, 6, 6, 6, 7, 6, 9, 7, 2, 5, 1, 3, 9, 7, 5, 3, 7, 7, 2, 5, 9, 9, 1, 9, 0, 4, 7, 0, 7, 3, 3, 5, 8, 6, 2, 1, 8, 7, 6, 9, 5, 9, 3, 2, 3, 3, 6, 7, 3, 6, 7, 5, 0, 3, 5, 1, 1, 4, 8, 5, 4, 3, 3, 8, 6, 3, 9, 3, 5, 8, 4, 0, 2, 9, 1, 7, 6, 4, 8, 3, 9, 6, 6, 5, 8, 4, 0, 8, 0, 9, 7, 1, 7, 8, 6, 8, 8, 6, 4, 6, 1, 3, 9, 3, 6, 5, 9, 5, 7, 3, 9, 3, 8, 1, 9, 7, 9, 8, 9, 4, 6, 5, 6, 8, 9, 2, 5, 8, 6, 7, 8, 3, 0, 5, 8, 8, 4, 9, 1, 9, 0, 6, 0, 5, 0, 7, 2, 6, 3, 9, 1, 8, 9, 3, 1, 3, 3, 5, 3, 6, 4, 5, 3, 5, 7, 3, 1, 8, 9, 5, 9, 4, 8, 2, 9, 5, 3, 1, 6, 1, 3, 6, 7, 5, 7, 6, 9, 9, 7, 1, 0, 0, 9, 8, 1, 4, 6, 0, 1, 2, 3, 2, 2, 1, 4, 1, 5, 7, 3, 1, 5, 5, 3, 6, 9, 6, 7, 5, 3, 8, 5, 9, 2, 7, 3, 2, 2, 1, 2, 3, 7, 7, 6, 4, 2, 8, 9, 9, 9, 6, 7, 0, 3, 9, 1, 7, 2, 2, 0, 3, 4, 0, 3, 9, 2, 2, 0, 6, 4, 7, 2, 6, 3, 0, 1, 5, 4, 3, 7, 7, 8, 2, 1, 8]\n"
     ]
    }
   ],
   "source": [
    "convNet.eval()\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device('cpu')\n",
    "convNet = convNet.to(device)\n",
    "predict_all = []\n",
    "files_all = []\n",
    "for i, (imgs, files) in enumerate(test_loader):\n",
    "    # print(int(round(time.time() * 1000)))\n",
    "    imgs = imgs.float().to(device)\n",
    "    outputs = convNet(imgs)\n",
    "    predict = torch.argmax(F.softmax(outputs, dim=1), dim=1)\n",
    "    # print(int(round(time.time() * 1000)))\n",
    "    print(f\"\"\"i = {i},  \n",
    "    predict = {predict}\"\"\")\n",
    "    predict_all += predict.tolist()\n",
    "    files_all += list(files)\n",
    "print(files_all)\n",
    "print(predict_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}