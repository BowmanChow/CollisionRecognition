{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "True\n['toothpaste_box', 'whiteboard_spray', 'toy_elephant', 'green_basketball', '061_foam_brick', 'shiny_toy_gun', 'salt_cylinder', 'strawberry', 'stanley_screwdriver', 'yellow_block']\n"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import torch.utils.data as data\n",
    "import torchvision.models as models\n",
    "import matplotlib.image as pli\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from PIL import ImageOps\n",
    "from PIL import ImageEnhance\n",
    "import random\n",
    "import math\n",
    "import pickle\n",
    "import glob\n",
    "import librosa\n",
    "import os\n",
    "import time\n",
    "import scipy.signal as ss\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "print(torch.cuda.is_available())\n",
    "path = './dataset/train'\n",
    "labels = os.listdir(path)\n",
    "audio_files = {l: glob.glob(f'{path}/{l}/*/*.pkl') for l in labels}\n",
    "print(labels)\n",
    "\n",
    "is_plot = False\n",
    "\n",
    "freq_length = 57\n",
    "time_length = 221\n",
    "trainingset_size = 10000\n",
    "batch_size = 64 if torch.cuda.is_available() else 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ImageSet(data.Dataset):\n",
    "    def __init__(self):\n",
    "        self.length = trainingset_size\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # print(index)\n",
    "        label = index % len(labels)\n",
    "        audio_file = random.choice(audio_files[labels[label]])\n",
    "        # audio_file = glob.glob(f'{path}/stanley_screwdriver/331/*.pkl')[0]\n",
    "\n",
    "        data = np.load(audio_file, allow_pickle=True)\n",
    "        audio = data['audio']\n",
    "        sample_rate = data['audio_samplerate']\n",
    "\n",
    "        stft_result = []\n",
    "        for i in range(4):\n",
    "            audio_resample = ss.resample(audio[:, i], audio.shape[0] // 4)\n",
    "            stft_re = ss.stft(audio_resample, nperseg=512, noverlap=384)[2]\n",
    "            stft_result.append(np.abs(stft_re))\n",
    "        stft_result = np.array(stft_result)\n",
    "        stft_result /= np.max(stft_result)\n",
    "        # print(np.unravel_index(np.argmax(stft_result), stft_result.shape))\n",
    "\n",
    "        time_mid = int(stft_result.shape[2] / 2)\n",
    "        time_left = time_mid - 100\n",
    "        time_right = time_left + time_length\n",
    "        audio_map = stft_result[:, 0:freq_length, time_left:time_right]\n",
    "\n",
    "        if is_plot:\n",
    "            print(audio_file)\n",
    "            print(f'audio shape = {audio.shape}')\n",
    "            plt.plot(audio[:, 3])\n",
    "            plt.show()\n",
    "            print(f'audio_resample.shape = {audio_resample.shape}')\n",
    "            plt.plot(audio_resample)\n",
    "            plt.show()\n",
    "            print(f'stft_result.shape = {stft_result.shape}')\n",
    "            print(time_left)\n",
    "            print(time_right)\n",
    "            print(f'audio_map.shape = {audio_map.shape}')\n",
    "\n",
    "            plt.imshow(audio_map[0], cmap='gray')\n",
    "            plt.show()\n",
    "            plt.imshow(audio_map[1], cmap='gray')\n",
    "            plt.show()\n",
    "            plt.imshow(audio_map[2], cmap='gray')\n",
    "            plt.show()\n",
    "            plt.imshow(audio_map[3], cmap='gray')\n",
    "            plt.show()\n",
    "\n",
    "        return audio_map, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "train_loader = data.DataLoader(ImageSet(), batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioCNN(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super(AudioCNN, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            # 57 221\n",
    "            nn.Conv2d(in_channels=4, out_channels=64,\n",
    "                      kernel_size=(3, 11)),\n",
    "            # 55 211\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=self.layer1[0].out_channels, out_channels=64,\n",
    "                      kernel_size=(3, 10), stride=(2, 3)),\n",
    "            # 27 68\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=self.layer2[0].out_channels,\n",
    "                      out_channels=128, kernel_size=(3, 5)),\n",
    "            # 25 64\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=self.layer3[0].out_channels,\n",
    "                      out_channels=128, kernel_size=(3, 7), stride=(2, 3)),\n",
    "            # 12 20\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.layer5 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=self.layer4[0].out_channels,\n",
    "                      out_channels=256, kernel_size=(3, 5)),\n",
    "            # 10 16\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(output_size=(1, 1))\n",
    "        self.fc = nn.Linear(self.layer5[0].out_channels, len(labels))\n",
    "\n",
    "    def forward(self, input):\n",
    "        out = self.layer1(input)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.layer5(out)\n",
    "        # print(out.shape)\n",
    "        out = self.avg_pool(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "convNet = AudioCNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "source": [
    "state_dict = torch.load('./ConvNet.model')\n",
    "convNet.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "i = 0,  loss = 1.1396876573562622,  accuracy = 0.734375\n",
      "i = 2,  loss = 1.2295805215835571,  accuracy = 0.5\n",
      "i = 4,  loss = 1.2568227052688599,  accuracy = 0.609375\n",
      "i = 6,  loss = 1.0423927307128906,  accuracy = 0.640625\n",
      "i = 8,  loss = 1.0872704982757568,  accuracy = 0.671875\n",
      "i = 10,  loss = 0.9369926452636719,  accuracy = 0.640625\n",
      "i = 12,  loss = 0.9394078254699707,  accuracy = 0.609375\n",
      "i = 14,  loss = 1.0458985567092896,  accuracy = 0.59375\n",
      "i = 16,  loss = 1.040963888168335,  accuracy = 0.59375\n",
      "i = 18,  loss = 0.9407866597175598,  accuracy = 0.6875\n",
      "i = 20,  loss = 0.8923607468605042,  accuracy = 0.703125\n",
      "i = 22,  loss = 0.8709472417831421,  accuracy = 0.65625\n",
      "i = 24,  loss = 0.7210776805877686,  accuracy = 0.75\n",
      "i = 26,  loss = 0.783420741558075,  accuracy = 0.734375\n",
      "i = 28,  loss = 0.8580514192581177,  accuracy = 0.59375\n",
      "i = 30,  loss = 0.8207448720932007,  accuracy = 0.734375\n",
      "i = 32,  loss = 0.7845686078071594,  accuracy = 0.671875\n",
      "i = 34,  loss = 0.6073460578918457,  accuracy = 0.78125\n",
      "i = 36,  loss = 0.7791450023651123,  accuracy = 0.6875\n",
      "i = 38,  loss = 0.6618667840957642,  accuracy = 0.796875\n",
      "i = 40,  loss = 0.7574124336242676,  accuracy = 0.703125\n",
      "i = 42,  loss = 0.5783249139785767,  accuracy = 0.8125\n",
      "i = 44,  loss = 0.7664582133293152,  accuracy = 0.75\n",
      "i = 46,  loss = 0.641679048538208,  accuracy = 0.78125\n",
      "i = 48,  loss = 0.6195716857910156,  accuracy = 0.78125\n",
      "i = 50,  loss = 0.6047534942626953,  accuracy = 0.78125\n",
      "i = 52,  loss = 0.8672531247138977,  accuracy = 0.703125\n",
      "i = 54,  loss = 0.6168091297149658,  accuracy = 0.75\n",
      "i = 56,  loss = 0.8383654952049255,  accuracy = 0.6875\n",
      "i = 58,  loss = 0.6175756454467773,  accuracy = 0.796875\n",
      "i = 60,  loss = 0.542847216129303,  accuracy = 0.859375\n",
      "i = 62,  loss = 0.9061291813850403,  accuracy = 0.640625\n",
      "i = 64,  loss = 0.5510607361793518,  accuracy = 0.796875\n",
      "i = 66,  loss = 0.6201074719429016,  accuracy = 0.75\n",
      "i = 68,  loss = 0.6098828911781311,  accuracy = 0.71875\n",
      "i = 70,  loss = 0.8335367441177368,  accuracy = 0.6875\n",
      "i = 72,  loss = 0.4565446078777313,  accuracy = 0.84375\n",
      "i = 74,  loss = 0.565554141998291,  accuracy = 0.796875\n",
      "i = 76,  loss = 0.3530721068382263,  accuracy = 0.9375\n",
      "i = 78,  loss = 0.6276655793190002,  accuracy = 0.78125\n",
      "i = 80,  loss = 0.454890638589859,  accuracy = 0.859375\n",
      "i = 82,  loss = 0.756803035736084,  accuracy = 0.734375\n",
      "i = 84,  loss = 0.4827876389026642,  accuracy = 0.828125\n",
      "i = 86,  loss = 0.7161125540733337,  accuracy = 0.75\n",
      "i = 88,  loss = 0.45012223720550537,  accuracy = 0.796875\n",
      "i = 90,  loss = 0.5243151187896729,  accuracy = 0.796875\n",
      "i = 92,  loss = 0.5412656664848328,  accuracy = 0.78125\n",
      "i = 94,  loss = 0.5766754746437073,  accuracy = 0.765625\n",
      "i = 96,  loss = 0.5891469717025757,  accuracy = 0.75\n",
      "i = 98,  loss = 0.5968284010887146,  accuracy = 0.8125\n",
      "i = 100,  loss = 0.546593964099884,  accuracy = 0.796875\n",
      "i = 102,  loss = 0.5465423464775085,  accuracy = 0.75\n",
      "i = 104,  loss = 0.5517269968986511,  accuracy = 0.828125\n",
      "i = 106,  loss = 0.43688300251960754,  accuracy = 0.84375\n",
      "i = 108,  loss = 0.37076336145401,  accuracy = 0.84375\n",
      "i = 110,  loss = 0.3314565122127533,  accuracy = 0.90625\n",
      "i = 112,  loss = 0.4749111235141754,  accuracy = 0.84375\n",
      "i = 114,  loss = 0.5399395823478699,  accuracy = 0.84375\n",
      "i = 116,  loss = 0.4862651228904724,  accuracy = 0.8125\n",
      "i = 118,  loss = 0.47556671500205994,  accuracy = 0.8125\n",
      "i = 120,  loss = 0.47287100553512573,  accuracy = 0.8125\n",
      "i = 122,  loss = 0.37984800338745117,  accuracy = 0.890625\n",
      "i = 124,  loss = 0.5163885951042175,  accuracy = 0.8125\n",
      "i = 126,  loss = 0.49612343311309814,  accuracy = 0.859375\n",
      "i = 128,  loss = 0.4769739806652069,  accuracy = 0.828125\n",
      "i = 130,  loss = 0.5335775017738342,  accuracy = 0.8125\n",
      "i = 132,  loss = 0.5995186567306519,  accuracy = 0.765625\n",
      "i = 134,  loss = 0.45444390177726746,  accuracy = 0.84375\n",
      "i = 136,  loss = 0.4865104556083679,  accuracy = 0.8125\n",
      "i = 138,  loss = 0.37800630927085876,  accuracy = 0.859375\n",
      "i = 140,  loss = 0.5295514464378357,  accuracy = 0.75\n",
      "i = 142,  loss = 0.40398821234703064,  accuracy = 0.890625\n",
      "i = 144,  loss = 0.742645800113678,  accuracy = 0.78125\n",
      "i = 146,  loss = 0.34403157234191895,  accuracy = 0.890625\n",
      "i = 148,  loss = 0.2665853202342987,  accuracy = 0.921875\n",
      "i = 150,  loss = 0.4917355179786682,  accuracy = 0.765625\n",
      "i = 152,  loss = 0.42977944016456604,  accuracy = 0.828125\n",
      "i = 154,  loss = 0.49367889761924744,  accuracy = 0.875\n",
      "i = 156,  loss = 0.5979616641998291,  accuracy = 0.875\n"
     ]
    }
   ],
   "source": [
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(convNet.parameters(), lr=0.01)\n",
    "\n",
    "convNet.train()\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device('cpu')\n",
    "convNet = convNet.to(device)\n",
    "\n",
    "for i, (imgs, lbs) in enumerate(train_loader):\n",
    "    # print(int(round(time.time() * 1000)))\n",
    "    imgs = imgs.float().to(device)\n",
    "    lbs = lbs.to(device)\n",
    "    outputs = convNet(imgs)\n",
    "    loss = loss_func(outputs, lbs)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    predict = torch.argmax(F.softmax(outputs, dim=1), dim=1)\n",
    "    # print(int(round(time.time() * 1000)))\n",
    "    if i % 2 == 0:\n",
    "        print(f\"i = {i},  loss = {loss},  accuracy = {float(sum(lbs == predict))/float(lbs.size(0))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存模型， 请谨慎操作， 会覆盖文件中的模型\n",
    "torch.save(convNet.state_dict(), './ConvNet.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}